{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 概念定义"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logistic 回归，虽然名字里有 “回归” 二字，但实际上是解决分类问题的一类线性模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 算法基本思想"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**假设函数**\n",
    "\n",
    "$$h_{\\theta}(x) = g(\\theta^Tx)$$\n",
    "$$g(z) = \\frac{1}{1+e^{-z}}$$\n",
    "其中 $\\theta$ 已包含偏置项，$g(z)$ 为Sigmoid函数\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**成本函数**（Cost Function）\n",
    "\n",
    "损失函数loss function:（式1.1-1）\n",
    "$$L(\\hat{y}^{(i)}, y^{(i)}) = -(ylog\\hat{y}+(1-y)log(1-\\hat{y}))$$\n",
    "\n",
    "成本函数cost Function:\n",
    "\n",
    "$$J(\\theta) = \\frac{1}{m}\\sum_{i=1}^mL(\\hat{y}^{(i)}, y^{(i)})$$\n",
    "\n",
    "其中 $\\hat{y}$ 为 $y$ 的预测值，由假设函数计算而来。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "普通的成本函数：\n",
    "$$L(\\hat{y}^{(i)}, y^{(i)}) = \\frac{(\\hat{y}-y)^2}{2}$$\n",
    "\n",
    "该函数非凸，梯度下降可能无法得到最优解，而（式1.1-1）是凸函数，很容易获得最优解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**迭代优化**\n",
    "\n",
    "梯度下降\n",
    "\n",
    "为了计算 $\\theta$ 值，执行以下步骤：\n",
    "\n",
    "$$Z = \\theta X$$\n",
    "\n",
    "$$A = g(Z)$$\n",
    "\n",
    "（式1.1-2）\n",
    "$$dZ = \\frac{\\partial J}{\\partial Z} = A-Y$$ \n",
    "\n",
    "$$d\\theta = dZ\\frac{dZ}{d\\theta} = XdZ^T$$\n",
    "\n",
    "$$d\\theta = d\\theta/m -> d\\theta = \\frac{1}{m}XdZ^T$$\n",
    "\n",
    "$$\\theta = \\theta - \\alpha d\\theta$$\n",
    "\n",
    "其中 $\\alpha$ 为学习率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**对式1.1-2的推导**\n",
    "\n",
    "$$\\frac{dJ}{dA} = -\\frac{Y}{A}+\\frac{1-Y}{1-A}$$\n",
    "\n",
    "$$\\frac{dA}{dZ}=g^\\prime(z) = g(z)(1-g(z)) = A(1-A)$$\n",
    "\n",
    "$$dZ = \\frac{dJ}{dA}\\cdot\\frac{dA}{dZ} = A-Y$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**决策边界**\n",
    "\n",
    "所谓决策边界就是能够把样本正确分类的一条边界，主要有线性决策边界(linear decision boundaries)和非线性决策边界(non-linear decision boundaries)\n",
    "\n",
    "决策边界是假设函数的属性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 损失函数的由来"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**涉及对 $\\theta$ 的最大似然估计**\n",
    "\n",
    "假定：\n",
    "$$P(y=1 | x;\\theta) = h_\\theta(x) = \\hat{y}$$\n",
    "$$P(y=0 | x;\\theta) = 1-h_\\theta(x) = 1-\\hat{y}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对 $\\theta$ 的条件最大似然估计：（式1.2-1）\n",
    "$$\\theta_{ML} = \\underset{\\theta}{argmax}P(Y | X;\\theta)$$\n",
    "\n",
    "似然函数：假设样本是独立同分布，概率相乘，然后左右两边同时取对数\n",
    "$$P(Y|X;\\theta) = \\prod_{i=1}^{m}P(y^{(i)}|x^{(i)};\\theta)$$\n",
    "\n",
    "$$=\\prod_{i=1}^{m}\\hat{y}^y(1-\\hat{y})^{1-y}$$\n",
    "\n",
    "$$logP(Y|X;\\theta) = log\\prod_{i=1}^{m}\\hat{y}^y(1-\\hat{y})^{1-y}$$\n",
    "\n",
    "$$=\\sum_{i=1}^{m}ylog\\hat{y}+(1-y)log(1-\\hat{y})$$\n",
    "\n",
    "则（式1.2-1）可以分解为：\n",
    "$$\\theta_{ML} = \\underset{\\theta}{argmax}\\sum_{i=1}^{m}logP(y^{(i)} | x^{(i)};\\theta)$$\n",
    "\n",
    "$$=\\underset{\\theta}{argmax}\\sum_{i=1}^{m}ylog\\hat{y}+(1-y)log(1-\\hat{y})$$\n",
    "\n",
    "所以损失函数定为：\n",
    "$$J(\\theta) = \\frac{1}{m}\\sum_{i=1}^mL(\\hat{y}^{(i)}, y^{(i)})$$\n",
    "$$=\\frac{1}{m}\\sum_{i=1}^m-(ylog\\hat{y}+(1-y)log(1-\\hat{y}))$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn中的LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn 中 logistic 回归在 `LogisticRegression` 类中实现了二分类（binary）、一对多分类（one-vs-rest）及多项式 logistic 回归，并带有可选的 L1 和 L2 正则化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">注意，scikit-learn的逻辑回归在默认情况下使用L2正则化，这样的方式在机器学习领域是常见的，在统计分析领域是不常见的。正则化的另一优势是提升数值稳定性。scikit-learn通过将C设置为很大的值实现无正则化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
